name: hgnetv2_b5_metric_learning_big_margin_drop_cliques_test_0_6_6folds${now:%d_%H_%M}
path_to_fold_checkpoints: artifacts_hgnetv2_b5_drop_cliques_test_0_6_6folds01_11_06/model_checkpoints
freeze_backbone_num_layers: 360
freeze_ln: true
description: Тест
environment:
  device: cuda:1
  seed: 3
raw_data_path: data/raw
artifacts_path: artifacts_${name}/
read_clique2versions:
  _target_: csi.training.data.dataset.read_clique2versions
  clique2versions_path: ${raw_data_path}/cliques2versions.tsv
read_filtered_clique2versions:
  _target_: csi.training.data.dataset.read_clique2versions
  clique2versions_path: ${raw_data_path}/cliques2versions_drop_cliques_test_0_6.tsv
split_cliques:
  _target_: csi.training.data.dataset.split_cliques
  n_splits: 6
num_classes: 46741
image_size: 224
data_transformations:
  _target_: torchvision.transforms.v2.Compose
  transforms:
  - _target_: csi.training.data.dataset.ToImage
  - _target_: torchvision.transforms.v2.Resize
    interpolation: 3
    size:
      - ${image_size}
      - ${image_size}
  - _target_: torchvision.transforms.v2.Normalize
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
batch_size: 200
train_data:
  dataset:
    _target_: csi.training.data.dataset.CoverDataset
    tracks_path: ${raw_data_path}/train
    transformations: ${data_transformations}
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    shuffle: true
    num_workers: 10
    prefetch_factor: 10
    persistent_workers: true
    pin_memory: true
    collate_fn:
      _target_: csi.training.data.collator.AugCollator
      augmentations:
        _target_: torchvision.transforms.v2.RandomChoice
        transforms:
        - _target_: csi.training.data.augmentations.GaussianNoise
          sigma: 1.5
          clip: false
        - _target_: csi.training.data.augmentations.GaussianBlur
          kernel_size: 3
          sigma:
          - 0.1
          - 2.0
        - _target_: csi.training.data.augmentations.Dummy
        p:
        - 0.5
        - 0.45
        - 0.05
val_data:
  dataset:
    _target_: csi.training.data.dataset.CoverDataset
    tracks_path: ${raw_data_path}/train
    transformations: ${data_transformations}
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    shuffle: false
    num_workers: 10
    prefetch_factor: 10
    persistent_workers: true
    pin_memory: true
test_data:
  test_ids_path: ${raw_data_path}/test_ids.npy
  dataset:
    _target_: csi.training.data.dataset.CoverDataset
    tracks_path: ${raw_data_path}/test
    transformations: ${data_transformations}
  dataloader:
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    shuffle: false
    num_workers: 10
    prefetch_factor: 10
    persistent_workers: true
    pin_memory: true
model:
  _target_: csi.base.model.model.TimmModel
  backbone_name: hgnetv2_b5
  emb_size: 512
  layer_norm_size:
    - 3
    - ${image_size}
    - ${image_size}
  calc_pos_embeddings: true
  num_classes: ${num_classes}
nearest_neighbors_search:
  normalize_embeddings: true
training:
  n_epochs: 50
  criterion_container:
    _target_: csi.training.criterion.container.CriterionContainer
    criterions:
    - _target_: csi.training.criterion.metric_learning.MetricLearner
      miner:
        _target_: pytorch_metric_learning.miners.TripletMarginMiner
        margin: 0.3
        type_of_triplets: semihard
        distance:
          _target_: pytorch_metric_learning.distances.CosineSimilarity
      loss_fn:
        _target_: pytorch_metric_learning.losses.TripletMarginLoss
        margin: 0.3
        distance:
          _target_: pytorch_metric_learning.distances.CosineSimilarity
    - _target_: csi.training.criterion.losses.CrossEntropy
    weight_strategies:
    - _target_: csi.training.criterion.weight_strategy.LinearWeightStrategy
      start: 2.5
      end: 0.2
      max_iter: 3000
    - _target_: csi.training.criterion.weight_strategy.ConstantWeightStrategy
      weight: 1
  grouped_model_parameters:
    _target_: csi.training.optimizers.utils.get_grouped_model_parameters
    base_params:
      lr: 0.0005
  optimizer:
    _target_: torch.optim.Adam
  scheduler:
    _target_: torch.optim.lr_scheduler.LinearLR
    start_factor: 0.1
    end_factor: 1.0
    total_iters: 1000
  gradient_accumulation_steps: 1
  gradient_clip_norm: 1.0
  ema:
    _target_: torch_ema.ExponentialMovingAverage
    decay: 0.997
  mixed_precision: false
  early_stopping_rounds: 2
  checkpoint_dir: ${artifacts_path}/model_checkpoints
submission_dir: ${artifacts_path}/submissions
mlflow:
  experiment_name: test-test
  run_name: ${name}
  push:
    _target_: csi.training.mlflow.experiment_logging.push_to_mlflow
    push_config: true
    push_metrics: true
    push_model: false
    push_log: true
    push_git_info: true
    push_submission: true
hydra_single_run_outputs_dir: ${hydra:run.dir}